{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "gnTcvkxn86zr",
        "outputId": "8be2700d-41e2-42af-d545-8a20c505698d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>div.output_scroll { height: 35em; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.io as pio\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import seaborn as sns\n",
        "from importlib import reload\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import warnings\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "# pd.set_option('max_colwidth', -1)\n",
        "display(HTML(\"<style>div.output_scroll { height: 35em; }</style>\"))\n",
        "\n",
        "reload(plt)\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format ='retina'\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# configure plotly graph objects\n",
        "pio.renderers.default = 'iframe'\n",
        "# pio.renderers.default = 'vscode'\n",
        "\n",
        "pio.templates[\"ck_template\"] = go.layout.Template(\n",
        "    layout_colorway = px.colors.sequential.Viridis,\n",
        "#     layout_hovermode = 'closest',\n",
        "#     layout_hoverdistance = -1,\n",
        "    layout_autosize=False,\n",
        "    layout_width=800,\n",
        "    layout_height=600,\n",
        "    layout_font = dict(family=\"Calibri Light\"),\n",
        "    layout_title_font = dict(family=\"Calibri\"),\n",
        "    layout_hoverlabel_font = dict(family=\"Calibri Light\"),\n",
        "#     plot_bgcolor=\"white\",\n",
        ")\n",
        "\n",
        "# pio.templates.default = 'seaborn+ck_template+gridon'\n",
        "pio.templates.default = 'ck_template+gridon'\n",
        "# pio.templates.default = 'seaborn+gridon'\n",
        "# pio.templates"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install the Kaggle package\n",
        "!pip install kaggle\n",
        "\n",
        "# Step 2: Upload your Kaggle API token\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "yQxCro1zVuTZ",
        "outputId": "9b241bb0-c70b-4c8b-85bd-b3b21c944814"
      },
      "execution_count": 2,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-333e70a3-fb92-45e6-8dbd-291c97d22cb0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-333e70a3-fb92-45e6-8dbd-291c97d22cb0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"mrsiddy\",\"key\":\"00b49b189856b15793e505e3bd64fb56\"}'}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 3: Create the Kaggle directory and move the API token there\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Step 4: Download the dataset using the Kaggle API\n",
        "!kaggle datasets download -d cnrieiit/mqttset\n",
        "\n",
        "# Step 5: Unzip the downloaded dataset\n",
        "!unzip mqttset.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAb6DqcVRRQ5",
        "outputId": "0898bf3a-1505-4c72-bf3d-691876f345cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/cnrieiit/mqttset\n",
            "License(s): CC-BY-NC-SA-4.0\n",
            "Downloading mqttset.zip to /content\n",
            " 99% 873M/879M [00:13<00:00, 64.3MB/s]\n",
            "100% 879M/879M [00:13<00:00, 68.7MB/s]\n",
            "Archive:  mqttset.zip\n",
            "  inflating: Data/CSV/bruteforce.csv  \n",
            "  inflating: Data/CSV/flood.csv      \n",
            "  inflating: Data/CSV/legitimate_1w.csv  \n",
            "  inflating: Data/CSV/malaria.csv    \n",
            "  inflating: Data/CSV/malformed.csv  \n",
            "  inflating: Data/CSV/slowite.csv    \n",
            "  inflating: Data/FINAL_CSV/mqttdataset_reduced.csv  \n",
            "  inflating: Data/FINAL_CSV/test30.csv  \n",
            "  inflating: Data/FINAL_CSV/test30_augmented.csv  \n",
            "  inflating: Data/FINAL_CSV/test30_reduced.csv  \n",
            "  inflating: Data/FINAL_CSV/train70.csv  \n",
            "  inflating: Data/FINAL_CSV/train70_augmented.csv  \n",
            "  inflating: Data/FINAL_CSV/train70_reduced.csv  \n",
            "  inflating: Data/PCAP/bruteforce.pcapng  \n",
            "  inflating: Data/PCAP/capture_1w.pcap  \n",
            "  inflating: Data/PCAP/capture_flood.pcap  \n",
            "  inflating: Data/PCAP/capture_malariaDoS.pcap  \n",
            "  inflating: Data/PCAP/malformed.pcap  \n",
            "  inflating: Data/PCAP/slowite.pcap  \n",
            "  inflating: Data/README.md          \n",
            "  inflating: code/parser/rawparsing_augmented.py  \n",
            "  inflating: code/parser/rawparsing_normal.py  \n",
            "  inflating: code/processingdata_ml.py  \n",
            "  inflating: requirements.txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets\n",
        "dftrain = pd.read_csv(\"./Data/FINAL_CSV/train70_reduced.csv\")\n",
        "dftest = pd.read_csv(\"./Data/FINAL_CSV/test30_reduced.csv\")\n"
      ],
      "metadata": {
        "id": "l9befY4u9X4k"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dftrain.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "lJLaK4jcXrK-",
        "outputId": "1c880906-3f58-4c04-fc34-f7253a294ad6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    tcp.flags  tcp.time_delta  tcp.len mqtt.conack.flags  mqtt.conack.flags.reserved  mqtt.conack.flags.sp  mqtt.conack.val  mqtt.conflag.cleansess  mqtt.conflag.passwd  mqtt.conflag.qos  mqtt.conflag.reserved  mqtt.conflag.retain  mqtt.conflag.uname  mqtt.conflag.willflag mqtt.conflags  mqtt.dupflag mqtt.hdrflags  mqtt.kalive  mqtt.len                                           mqtt.msg  mqtt.msgid  mqtt.msgtype  mqtt.proto_len mqtt.protoname  mqtt.qos  mqtt.retain  mqtt.sub.qos  mqtt.suback.qos  mqtt.ver  mqtt.willmsg  mqtt.willmsg_len  mqtt.willtopic  mqtt.willtopic_len      target\n",
              "0  0x00000018        0.998867       10                 0                         0.0                   0.0              0.0                     0.0                  0.0               0.0                    0.0                  0.0                 0.0                    0.0             0           0.0    0x00000030          0.0       8.0                                                 32         0.0           3.0             0.0              0       0.0          0.0           0.0              0.0       0.0           0.0               0.0             0.0                 0.0  legitimate\n",
              "1  0x00000010        0.000067     1460                 0                         0.0                   0.0              0.0                     0.0                  0.0               0.0                    0.0                  0.0                 0.0                    0.0             0           0.0    0x00000032          0.0     169.0  6361653943666144654266454162444634326230633041...      2714.0           3.0             0.0              0       1.0          0.0           0.0              0.0       0.0           0.0               0.0             0.0                 0.0         dos\n",
              "2  0x00000010        0.000058     1460                 0                         0.0                   0.0              0.0                     0.0                  0.0               0.0                    0.0                  0.0                 0.0                    0.0             0           0.0    0x00000032          0.0     163.0  4232646141394333463334613232626446326646383446...      1548.0           3.0             0.0              0       1.0          0.0           0.0              0.0       0.0           0.0               0.0             0.0                 0.0         dos\n",
              "3  0x00000018        0.000227       10                 0                         0.0                   0.0              0.0                     0.0                  0.0               0.0                    0.0                  0.0                 0.0                    0.0             0           0.0    0x00000030          0.0       8.0                                                 32         0.0           3.0             0.0              0       0.0          0.0           0.0              0.0       0.0           0.0               0.0             0.0                 0.0  legitimate\n",
              "4  0x00000018        0.000236       16                 0                         0.0                   0.0              0.0                     0.0                  0.0               0.0                    0.0                  0.0                 0.0                    0.0             0           0.0    0x00000040          0.0       2.0                                                  0      2800.0           4.0             0.0              0       0.0          0.0           0.0              0.0       0.0           0.0               0.0             0.0                 0.0         dos"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b0bae037-c2a3-4e1e-9d7e-d411949cf175\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tcp.flags</th>\n",
              "      <th>tcp.time_delta</th>\n",
              "      <th>tcp.len</th>\n",
              "      <th>mqtt.conack.flags</th>\n",
              "      <th>mqtt.conack.flags.reserved</th>\n",
              "      <th>mqtt.conack.flags.sp</th>\n",
              "      <th>mqtt.conack.val</th>\n",
              "      <th>mqtt.conflag.cleansess</th>\n",
              "      <th>mqtt.conflag.passwd</th>\n",
              "      <th>mqtt.conflag.qos</th>\n",
              "      <th>mqtt.conflag.reserved</th>\n",
              "      <th>mqtt.conflag.retain</th>\n",
              "      <th>mqtt.conflag.uname</th>\n",
              "      <th>mqtt.conflag.willflag</th>\n",
              "      <th>mqtt.conflags</th>\n",
              "      <th>mqtt.dupflag</th>\n",
              "      <th>mqtt.hdrflags</th>\n",
              "      <th>mqtt.kalive</th>\n",
              "      <th>mqtt.len</th>\n",
              "      <th>mqtt.msg</th>\n",
              "      <th>mqtt.msgid</th>\n",
              "      <th>mqtt.msgtype</th>\n",
              "      <th>mqtt.proto_len</th>\n",
              "      <th>mqtt.protoname</th>\n",
              "      <th>mqtt.qos</th>\n",
              "      <th>mqtt.retain</th>\n",
              "      <th>mqtt.sub.qos</th>\n",
              "      <th>mqtt.suback.qos</th>\n",
              "      <th>mqtt.ver</th>\n",
              "      <th>mqtt.willmsg</th>\n",
              "      <th>mqtt.willmsg_len</th>\n",
              "      <th>mqtt.willtopic</th>\n",
              "      <th>mqtt.willtopic_len</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.998867</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0x00000010</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>1460</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>169.0</td>\n",
              "      <td>6361653943666144654266454162444634326230633041...</td>\n",
              "      <td>2714.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0x00000010</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>1460</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>163.0</td>\n",
              "      <td>4232646141394333463334613232626446326646383446...</td>\n",
              "      <td>1548.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000227</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000030</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>legitimate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0x00000018</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>16</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0x00000040</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2800.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>dos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0bae037-c2a3-4e1e-9d7e-d411949cf175')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b0bae037-c2a3-4e1e-9d7e-d411949cf175 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b0bae037-c2a3-4e1e-9d7e-d411949cf175');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ce52d10-9c49-471b-8640-15e7d88d5fb4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ce52d10-9c49-471b-8640-15e7d88d5fb4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ce52d10-9c49-471b-8640-15e7d88d5fb4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dftrain"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftrain['target'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvH6hmxu0z-3",
        "outputId": "c72185eb-5a61-4926-f6ef-61b32529d768"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['legitimate', 'dos', 'malformed', 'bruteforce', 'slowite', 'flood'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess data\n",
        "def preprocess_data(df):\n",
        "    df = df.astype('category')\n",
        "    cat_columns = df.select_dtypes(['category']).columns\n",
        "    df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)\n",
        "    return df"
      ],
      "metadata": {
        "id": "iMMCgZRkmSzY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess training data\n",
        "dftrain = preprocess_data(dftrain)\n",
        "dftest = preprocess_data(dftest)"
      ],
      "metadata": {
        "id": "EPEEn28amYgW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess test data\n",
        "x_train = dftrain.drop('target', axis=1)\n",
        "y_train = dftrain['target']\n",
        "x_test = dftest.drop('target', axis=1)\n",
        "y_test = dftest['target']\n",
        "\n",
        "print(\"Ready to generate train and test datasets\")"
      ],
      "metadata": {
        "id": "v6Bn9oVgmvYD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b232397-9606-49da-9e79-93cd6ef94538"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to generate train and test datasets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "def select_top_k_pearson(X, y, k=20):\n",
        "    correlations = []\n",
        "    for col in X.columns:\n",
        "        corr, _ = pearsonr(X[col], y)\n",
        "        correlations.append(abs(corr))\n",
        "\n",
        "    top_k_indices = np.argsort(correlations)[-k:]\n",
        "    return X.columns[top_k_indices]\n",
        "\n",
        "def select_top_k_chi2(X, y, k=20):\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    chi2_selector = SelectKBest(chi2, k=k)\n",
        "    chi2_selector.fit(X_scaled, y)\n",
        "    return X.columns[chi2_selector.get_support()]\n",
        "\n",
        "def select_top_k_anova(X, y, k=20):\n",
        "    anova_selector = SelectKBest(f_classif, k=k)\n",
        "    anova_selector.fit(X, y)\n",
        "    return X.columns[anova_selector.get_support()]\n",
        "\n",
        "def select_top_k_rfe(X, y, k=20):\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "    rfe_selector = RFE(estimator=model, n_features_to_select=k, step=1)\n",
        "    rfe_selector.fit(X, y)\n",
        "    return X.columns[rfe_selector.get_support()]\n",
        "\n",
        "\n",
        "top_20_pearson = select_top_k_pearson(x_train, y_train, k=20)\n",
        "top_20_chi2 = select_top_k_chi2(x_train, y_train, k=20)\n",
        "top_20_anova = select_top_k_anova(x_train, y_train, k=20)\n",
        "top_20_rfe = select_top_k_rfe(x_train, y_train, k=20)\n",
        "\n",
        "#test\n",
        "top_20_pearson = select_top_k_pearson(x_test, y_test, k=20)\n",
        "top_20_chi2 = select_top_k_chi2(x_test, y_test, k=20)\n",
        "top_20_anova = select_top_k_anova(x_test, y_test, k=20)\n",
        "top_20_rfe = select_top_k_rfe(x_test, y_test, k=20)"
      ],
      "metadata": {
        "id": "uSGU8NB-HOBw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selected_features = set(top_20_rfe)\n",
        "final_selected_features = list(selected_features)[:20]\n",
        "\n",
        "X_selected = x_train[final_selected_features]\n",
        "\n",
        "# Combine the selected features\n",
        "# selected_features = set(top_20_pearson).union(set(top_20_chi2)).union(set(top_20_anova))\n",
        "# Only pearson features\n",
        "selected_features = set(top_20_rfe)\n",
        "final_selected_features = list(selected_features)[:20]  # If you want exactly 20 features\n",
        "\n",
        "# Filter the dataset to keep only the selected features\n",
        "X_selected_test = x_test[final_selected_features]"
      ],
      "metadata": {
        "id": "xG0nHrZzWZIr"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = X_selected.values, X_selected_test.values, y_train.values, y_test.values"
      ],
      "metadata": {
        "id": "S1BOiBKhHVHD"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X_train_tensor = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "kJ1rnyY4ozWP"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYS-MNwZ2dJE",
        "outputId": "942aa332-046b-4105-d462-de89f66c965d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([231646, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lora-adapters peft"
      ],
      "metadata": {
        "id": "GzVQ5LGFozeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f543e5e-0643-4f9c-92ff-95bbfba3a4e4"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lora-adapters in /usr/local/lib/python3.10/dist-packages (0.1.4)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TABNET with LoRA"
      ],
      "metadata": {
        "id": "rQuBJXb4jwcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade peft"
      ],
      "metadata": {
        "id": "QtDTqsD3-Kkn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623dac75-6a5c-450a-9c60-5163941bc8e1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.3.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.5)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.32.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.6.20)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.19.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.7.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sparsemax import Sparsemax\n",
        "import torch\n",
        "from peft import LoraConfig"
      ],
      "metadata": {
        "id": "d1XtacxSl2tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "\n",
        "# GLU Block\n",
        "def glu(act, n_units):\n",
        "    return act[:, :n_units] * torch.sigmoid(act[:, n_units:])\n",
        "\n",
        "class LoRALinear(nn.Module):\n",
        "    def __init__(self, in_features, out_features, rank, alpha=1):\n",
        "        super(LoRALinear, self).__init__()\n",
        "        self.rank = rank\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # Original weight is frozen during training\n",
        "        self.orig_weight = nn.Parameter(torch.Tensor(out_features, in_features), requires_grad=False)\n",
        "        nn.init.kaiming_uniform_(self.orig_weight, a=math.sqrt(5))\n",
        "\n",
        "        # Low-rank matrices U and V\n",
        "        self.U = nn.Parameter(torch.Tensor(out_features, rank))\n",
        "        self.V = nn.Parameter(torch.Tensor(rank, in_features))\n",
        "        nn.init.kaiming_normal_(self.U)\n",
        "        nn.init.kaiming_normal_(self.V)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weight = self.orig_weight + self.alpha * self.U @ self.V\n",
        "        return F.linear(x, weight)\n",
        "\n",
        "    def extra_repr(self):\n",
        "        return 'in_features={}, out_features={}, rank={}, alpha={}'.format(\n",
        "            self.orig_weight.size(1), self.orig_weight.size(0), self.rank, self.alpha\n",
        "        )\n",
        "\n",
        "class TabNetModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_features=56,\n",
        "        feature_dims=56,\n",
        "        output_dim=56,\n",
        "        num_decision_steps=6,\n",
        "        relaxation_factor=0.5,\n",
        "        batch_momentum=0.001,\n",
        "        virtual_batch_size=2,\n",
        "        num_classes=2,\n",
        "        epsilon=0.00001\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.feature_dims = feature_dims\n",
        "        self.output_dim = output_dim\n",
        "        self.num_decision_steps = num_decision_steps\n",
        "        self.relaxation_factor = relaxation_factor\n",
        "        self.batch_momentum = batch_momentum\n",
        "        self.virtual_batch_size = virtual_batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.feature_transform_linear1 = LoRALinear(num_features, self.feature_dims * 2, rank=16)\n",
        "        self.BN = torch.nn.BatchNorm1d(num_features, momentum=batch_momentum)\n",
        "        self.BN1 = torch.nn.BatchNorm1d(self.feature_dims * 2, momentum=batch_momentum)\n",
        "\n",
        "        self.feature_transform_linear2 = torch.nn.Linear(self.feature_dims * 2, self.feature_dims * 2, bias=False)\n",
        "        self.feature_transform_linear3 = torch.nn.Linear(self.feature_dims, self.feature_dims * 2, bias=False)\n",
        "        self.feature_transform_linear4 = torch.nn.Linear(self.feature_dims * 2, self.feature_dims * 2, bias=False)\n",
        "\n",
        "        self.mask_linear_layer = torch.nn.Linear(self.feature_dims * 2 - output_dim, self.num_features, bias=False)\n",
        "        self.BN2 = torch.nn.BatchNorm1d(self.num_features, momentum=batch_momentum)\n",
        "\n",
        "        self.final_classifier_layer = torch.nn.Linear(self.output_dim, self.num_classes, bias=False)\n",
        "        self.sparsemax = nn.Softmax(dim=1)  # Changed to nn.Softmax for compatibility\n",
        "\n",
        "    def encoder(self, data):\n",
        "        batch_size = data.shape[0]\n",
        "        features = self.BN(data)\n",
        "        output_aggregated = torch.zeros([batch_size, self.output_dim], dtype=torch.float).to(device)\n",
        "\n",
        "        masked_features = features\n",
        "        mask_values = torch.zeros([batch_size, self.num_features]).to(device)\n",
        "\n",
        "        aggregated_mask_values = torch.zeros([batch_size, self.num_features]).to(device)\n",
        "        complemantary_aggregated_mask_values = torch.ones([batch_size, self.num_features]).to(device)\n",
        "\n",
        "        total_entropy = 0\n",
        "\n",
        "        for ni in range(self.num_decision_steps):\n",
        "            if ni == 0:\n",
        "                transform_f1 = self.feature_transform_linear1(masked_features)\n",
        "                norm_transform_f1 = self.BN1(transform_f1)\n",
        "                transform_f2 = self.feature_transform_linear2(norm_transform_f1)\n",
        "                norm_transform_f2 = self.BN1(transform_f2)\n",
        "            else:\n",
        "                transform_f1 = self.feature_transform_linear1(masked_features)\n",
        "                norm_transform_f1 = self.BN1(transform_f1)\n",
        "                transform_f2 = self.feature_transform_linear2(norm_transform_f1)\n",
        "                norm_transform_f2 = self.BN1(transform_f2)\n",
        "                transform_f2 = (glu(norm_transform_f2, self.feature_dims) + transform_f1[:, :self.feature_dims]) * np.sqrt(0.5)\n",
        "                transform_f3 = self.feature_transform_linear3(transform_f2)\n",
        "                norm_transform_f3 = self.BN1(transform_f3)\n",
        "                transform_f4 = self.feature_transform_linear4(norm_transform_f3)\n",
        "                norm_transform_f4 = self.BN1(transform_f4)\n",
        "                transform_f4 = (glu(norm_transform_f4, self.feature_dims) + transform_f3[:, :self.feature_dims]) * np.sqrt(0.5)\n",
        "                decision_out = torch.nn.ReLU(inplace=True)(transform_f4[:, :self.output_dim])\n",
        "                output_aggregated = torch.add(decision_out, output_aggregated)\n",
        "                scale_agg = torch.sum(decision_out, axis=1, keepdim=True) / (self.num_decision_steps - 1)\n",
        "                aggregated_mask_values = torch.add(aggregated_mask_values, mask_values * scale_agg)\n",
        "                features_for_coef = transform_f4[:, :]\n",
        "                if ni < (self.num_decision_steps - 1):\n",
        "                    mask_linear_layer = self.mask_linear_layer(features_for_coef)\n",
        "                    mask_linear_norm = self.BN2(mask_linear_layer)\n",
        "                    mask_linear_norm = torch.mul(mask_linear_norm, complemantary_aggregated_mask_values)\n",
        "                    mask_values = self.sparsemax(mask_linear_norm)\n",
        "                    complemantary_aggregated_mask_values = torch.mul(complemantary_aggregated_mask_values, self.relaxation_factor - mask_values)\n",
        "                    total_entropy = torch.add(total_entropy, torch.mean(torch.sum(-mask_values * torch.log(mask_values + self.epsilon), axis=1)) / (self.num_decision_steps - 1))\n",
        "                    masked_features = torch.mul(mask_values, features)\n",
        "\n",
        "        return output_aggregated, total_entropy\n",
        "\n",
        "    def classify(self, output_logits):\n",
        "        logits = self.final_classifier_layer(output_logits)\n",
        "        predictions = F.softmax(logits, dim=1)\n",
        "        return logits, predictions"
      ],
      "metadata": {
        "id": "X-aSPzEoeU4R"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "frjJRM0Pdevc"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load saved model\n",
        "num_features = X_test_tensor.shape[1]\n",
        "model = TabNetModel(num_features=num_features, num_classes=2)\n",
        "\n",
        "# Load model weights onto CPU\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/TabLoRA_pretrained_models/tabnet_unsw_v2_rfe.pt\", map_location=torch.device('cpu')))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Zero-shot testing\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)\n",
        "    y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    output, _ = model.encoder(X_test_tensor)\n",
        "    logits, predictions = model.classify(output)\n",
        "    predicted_labels = torch.argmax(predictions, dim=1)"
      ],
      "metadata": {
        "id": "83VlRIqWkY-T"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_tensor = torch.where(y_train_tensor > 0, torch.tensor(1), y_train_tensor)\n",
        "y_test_tensor = torch.where(y_test_tensor > 0, torch.tensor(1), y_test_tensor)\n"
      ],
      "metadata": {
        "id": "x3MOzCvxkY7h"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# person\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# Zero-shot testing\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)\n",
        "    y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    output, _ = model.encoder(X_test_tensor)\n",
        "    logits, predictions = model.classify(output)\n",
        "    predicted_labels = torch.argmax(predictions, dim=1)\n",
        "\n",
        "y_true = y_test_tensor.cpu().numpy()\n",
        "y_pred = predicted_labels.cpu().numpy()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (predicted_labels == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
        "print(f'Zero-shot testing accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-zmJQsL4lEr",
        "outputId": "be39e3a6-b82a-49b4-8b0d-85796f88c000"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot testing accuracy: 0.7192\n",
            "Precision: 0.9035\n",
            "Recall: 0.7192\n",
            "F1 Score: 0.8002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "#anova\n",
        "\n",
        "# Zero-shot testing\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)\n",
        "    y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    output, _ = model.encoder(X_test_tensor)\n",
        "    logits, predictions = model.classify(output)\n",
        "    predicted_labels = torch.argmax(predictions, dim=1)\n",
        "\n",
        "y_true = y_test_tensor.cpu().numpy()\n",
        "y_pred = predicted_labels.cpu().numpy()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (predicted_labels == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
        "print(f'Zero-shot testing accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yRVX1_T7Y2M",
        "outputId": "c52c79d6-ac08-4157-eec0-198c8450e609"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot testing accuracy: 0.4621\n",
            "Precision: 0.8787\n",
            "Recall: 0.4621\n",
            "F1 Score: 0.6034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rfe k selection\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# Zero-shot testing\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)\n",
        "    y_test_tensor = y_test_tensor.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    output, _ = model.encoder(X_test_tensor)\n",
        "    logits, predictions = model.classify(output)\n",
        "    predicted_labels = torch.argmax(predictions, dim=1)\n",
        "\n",
        "y_true = y_test_tensor.cpu().numpy()\n",
        "y_pred = predicted_labels.cpu().numpy()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (predicted_labels == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
        "print(f'Zero-shot testing accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision = precision_score(y_true, y_pred, average='weighted')\n",
        "recall = recall_score(y_true, y_pred, average='weighted')\n",
        "f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jbt61IkSUPoX",
        "outputId": "f8fe871a-0697-4fbf-a02f-62eae93f1d26"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-shot testing accuracy: 0.5368\n",
            "Precision: 0.9505\n",
            "Recall: 0.5368\n",
            "F1 Score: 0.6589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few-shots transfer learning"
      ],
      "metadata": {
        "id": "3QdRPpSS0L-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "num_features = X_train_tensor.shape[1]\n",
        "model = TabNetModel(num_features=num_features, num_classes=2)\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/TabLoRA_pretrained_models/tabnet_bot_iot_v2_rfe.pt\"))\n",
        "model = model.to(device)\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    if 'U' in name or 'V' in name:\n",
        "        param.requires_grad = True\n",
        "    else:\n",
        "        param.requires_grad = False\n",
        "\n",
        "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def train_model(model, train_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, _ = model.encoder(X_batch)\n",
        "            loss = loss_function(model.classify(output)[0], y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "train_model(model, train_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojR6Bsyo0Lab",
        "outputId": "88622142-dde3-47cc-ba7f-f209b6bcffdf"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.11543825326194132\n",
            "Epoch 2, Loss: 0.08810775496749959\n",
            "Epoch 3, Loss: 0.07763617301683935\n",
            "Epoch 4, Loss: 0.07035979143541965\n",
            "Epoch 5, Loss: 0.06755153415210093\n",
            "Epoch 6, Loss: 0.06572565134152904\n",
            "Epoch 7, Loss: 0.06459729390975232\n",
            "Epoch 8, Loss: 0.06375047953873976\n",
            "Epoch 9, Loss: 0.06303270533256418\n",
            "Epoch 10, Loss: 0.06229372694753934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pearson\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, average_precision_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def evaluate_model(model, X_test_tensor, y_test_tensor):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    X_test_batch, y_test_batch = X_test_tensor.numpy(), y_test_tensor.numpy()\n",
        "    X_test_batch = torch.tensor(X_test_batch)\n",
        "    y_test_batch = torch.tensor(y_test_batch)\n",
        "    X_test_batch, y_test_batch = X_test_batch.to(device), y_test_batch.to(device)\n",
        "    output, _ = model.encoder(X_test_batch)\n",
        "    logits, predictions = model.classify(output)\n",
        "    print(logits.shape, predictions.shape)\n",
        "    accuracy = accuracy_score(y_test_batch.cpu(), logits.argmax(dim=1).cpu())\n",
        "    f1 = f1_score(y_test_batch.cpu(), predictions.argmax(dim=1).cpu())\n",
        "    precision, recall, _ = precision_recall_curve(y_test_batch.cpu(), predictions[:, 1].cpu())\n",
        "    average_precision = average_precision_score(y_test_batch.cpu(), predictions[:, 1].cpu())\n",
        "\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"F1 Score:\", f1)\n",
        "    print(\"Average Precision:\", average_precision)\n",
        "\n",
        "  return accuracy, f1, average_precision\n",
        "\n",
        "accuracy, f1, average_precision = evaluate_model(model, X_test_tensor, y_test_tensor)"
      ],
      "metadata": {
        "id": "e1DLpEHUkY4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb9b437d-75bd-4848-c9d4-b23a21596c4f"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([99290, 2]) torch.Size([99290, 2])\n",
            "Accuracy: 0.9565817302850237\n",
            "F1 Score: 0.9777981490732491\n",
            "Average Precision: 0.9901014167554516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ix0bYA1okY1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#anova\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, average_precision_score, recall_score\n",
        "\n",
        "def evaluate_model(model, X_test_tensor, y_test_tensor):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X_test_batch, y_test_batch = X_test_tensor.numpy(), y_test_tensor.numpy()\n",
        "\n",
        "        X_test_batch = torch.tensor(X_test_batch).to(device)\n",
        "        y_test_batch = torch.tensor(y_test_batch).to(device)\n",
        "\n",
        "        output, _ = model.encoder(X_test_batch)\n",
        "        logits, predictions = model.classify(output)\n",
        "\n",
        "        accuracy = accuracy_score(y_test_batch.cpu(), logits.argmax(dim=1).cpu())\n",
        "        f1 = f1_score(y_test_batch.cpu(), predictions.argmax(dim=1).cpu())\n",
        "        recall = recall_score(y_test_batch.cpu(), predictions.argmax(dim=1).cpu())\n",
        "        precision, recall_curve, _ = precision_recall_curve(y_test_batch.cpu(), predictions[:, 1].cpu())\n",
        "        average_precision = average_precision_score(y_test_batch.cpu(), predictions[:, 1].cpu())\n",
        "\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"F1 Score:\", f1)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"Average Precision:\", average_precision)\n",
        "\n",
        "    return accuracy, f1, recall, average_precision\n",
        "\n",
        "accuracy, f1, recall, average_precision = evaluate_model(model, X_test_tensor, y_test_tensor)\n"
      ],
      "metadata": {
        "id": "_dWIsSSTkYrd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2101e94-9a37-4ec1-d408-95b954d41080"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.443498841776614\n",
            "F1 Score: 0.6141653108394026\n",
            "Recall: 0.4632132211209303\n",
            "Average Precision: 0.919195917158424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rfe\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve, average_precision_score, recall_score\n",
        "\n",
        "def evaluate_model(model, X_test_tensor, y_test_tensor):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        X_test_batch, y_test_batch = X_test_tensor.numpy(), y_test_tensor.numpy()\n",
        "\n",
        "        X_test_batch = torch.tensor(X_test_batch).to(device)\n",
        "        y_test_batch = torch.tensor(y_test_batch).to(device)\n",
        "\n",
        "        output, _ = model.encoder(X_test_batch)\n",
        "        logits, predictions = model.classify(output)\n",
        "\n",
        "        accuracy = accuracy_score(y_test_batch.cpu(), logits.argmax(dim=1).cpu())\n",
        "        f1 = f1_score(y_test_batch.cpu(), predictions.argmax(dim=1).cpu())\n",
        "        recall = recall_score(y_test_batch.cpu(), predictions.argmax(dim=1).cpu())\n",
        "        precision, recall_curve, _ = precision_recall_curve(y_test_batch.cpu(), predictions[:, 1].cpu())\n",
        "        average_precision = average_precision_score(y_test_batch.cpu(), predictions[:, 1].cpu())\n",
        "\n",
        "        print(\"Accuracy:\", accuracy)\n",
        "        print(\"F1 Score:\", f1)\n",
        "        print(\"Recall:\", recall)\n",
        "        print(\"Average Precision:\", average_precision)\n",
        "\n",
        "    return accuracy, f1, recall, average_precision\n",
        "\n",
        "accuracy, f1, recall, average_precision = evaluate_model(model, X_test_tensor, y_test_tensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPSl_sZKXsQT",
        "outputId": "320f0684-6046-4ba2-b994-859d2d40e892"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6645986504179675\n",
            "F1 Score: 0.6818245748294922\n",
            "Recall: 0.7\n",
            "Average Precision: 0.6946559224564999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Going forward"
      ],
      "metadata": {
        "id": "cyLiZsyNdSpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# what if we want to train more lora layers :)\n",
        "class TabNetModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_features=56,\n",
        "        feature_dims=56,\n",
        "        output_dim=56,\n",
        "        num_decision_steps=6,\n",
        "        relaxation_factor=0.5,\n",
        "        batch_momentum=0.001,\n",
        "        virtual_batch_size=2,\n",
        "        num_classes=2,\n",
        "        epsilon=0.00001\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_features = num_features\n",
        "        self.feature_dims = feature_dims\n",
        "        self.output_dim = output_dim\n",
        "        self.num_decision_steps = num_decision_steps\n",
        "        self.relaxation_factor = relaxation_factor\n",
        "        self.batch_momentum = batch_momentum\n",
        "        self.virtual_batch_size = virtual_batch_size\n",
        "        self.num_classes = num_classes\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "        self.feature_transform_linear1 = LoRALinear(num_features, self.feature_dims * 2, rank=16)\n",
        "        self.feature_transform_linear2 = LoRALinear(self.feature_dims * 2, self.feature_dims * 2, rank=16)\n",
        "        self.feature_transform_linear3 = LoRALinear(self.feature_dims, self.feature_dims * 2, rank=16)\n",
        "        self.feature_transform_linear4 = LoRALinear(self.feature_dims * 2, self.feature_dims * 2, rank=16)\n",
        "\n",
        "        self.BN = torch.nn.BatchNorm1d(num_features, momentum=batch_momentum)\n",
        "        self.BN1 = torch.nn.BatchNorm1d(self.feature_dims * 2, momentum=batch_momentum)\n",
        "        self.BN2 = torch.nn.BatchNorm1d(self.num_features, momentum=batch_momentum)\n",
        "\n",
        "        self.mask_linear_layer = torch.nn.Linear(self.feature_dims * 2 - output_dim, self.num_features, bias=False)\n",
        "        self.final_classifier_layer = torch.nn.Linear(self.output_dim, self.num_classes, bias=False)\n",
        "        self.sparsemax = nn.Softmax(dim=1)\n",
        "\n",
        "    def encoder(self, data):\n",
        "        batch_size = data.shape[0]\n",
        "        features = self.BN(data)\n",
        "        output_aggregated = torch.zeros([batch_size, self.output_dim], dtype=torch.float).to(device)\n",
        "\n",
        "        masked_features = features\n",
        "        mask_values = torch.zeros([batch_size, self.num_features]).to(device)\n",
        "\n",
        "        aggregated_mask_values = torch.zeros([batch_size, self.num_features]).to(device)\n",
        "        complemantary_aggregated_mask_values = torch.ones([batch_size, self.num_features]).to(device)\n",
        "\n",
        "        total_entropy = 0\n",
        "\n",
        "        for ni in range(self.num_decision_steps):\n",
        "            if ni == 0:\n",
        "                transform_f1 = self.feature_transform_linear1(masked_features)\n",
        "                norm_transform_f1 = self.BN1(transform_f1)\n",
        "                transform_f2 = self.feature_transform_linear2(norm_transform_f1)\n",
        "                norm_transform_f2 = self.BN1(transform_f2)\n",
        "            else:\n",
        "                transform_f1 = self.feature_transform_linear1(masked_features)\n",
        "                norm_transform_f1 = self.BN1(transform_f1)\n",
        "                transform_f2 = self.feature_transform_linear2(norm_transform_f1)\n",
        "                norm_transform_f2 = self.BN1(transform_f2)\n",
        "                transform_f2 = (glu(norm_transform_f2, self.feature_dims) + transform_f1[:, :self.feature_dims]) * np.sqrt(0.5)\n",
        "                transform_f3 = self.feature_transform_linear3(transform_f2)\n",
        "                norm_transform_f3 = self.BN1(transform_f3)\n",
        "                transform_f4 = self.feature_transform_linear4(norm_transform_f3)\n",
        "                norm_transform_f4 = self.BN1(transform_f4)\n",
        "                transform_f4 = (glu(norm_transform_f4, self.feature_dims) + transform_f3[:, :self.feature_dims]) * np.sqrt(0.5)\n",
        "                decision_out = torch.nn.ReLU(inplace=True)(transform_f4[:, :self.output_dim])\n",
        "                output_aggregated = torch.add(decision_out, output_aggregated)\n",
        "                scale_agg = torch.sum(decision_out, axis=1, keepdim=True) / (self.num_decision_steps - 1)\n",
        "                aggregated_mask_values = torch.add(aggregated_mask_values, mask_values * scale_agg)\n",
        "                features_for_coef = transform_f4[:, :]\n",
        "                if ni < (self.num_decision_steps - 1):\n",
        "                    mask_linear_layer = self.mask_linear_layer(features_for_coef)\n",
        "                    mask_linear_norm = self.BN2(mask_linear_layer)\n",
        "                    mask_linear_norm = torch.mul(mask_linear_norm, complemantary_aggregated_mask_values)\n",
        "                    mask_values = self.sparsemax(mask_linear_norm)\n",
        "                    complemantary_aggregated_mask_values = torch.mul(complemantary_aggregated_mask_values, self.relaxation_factor - mask_values)\n",
        "                    total_entropy = torch.add(total_entropy, torch.mean(torch.sum(-mask_values * torch.log(mask_values + self.epsilon), axis=1)) / (self.num_decision_steps - 1))\n",
        "                    masked_features = torch.mul(mask_values, features)\n",
        "\n",
        "        return output_aggregated, total_entropy\n",
        "\n",
        "    def classify(self, output_logits):\n",
        "        logits = self.final_classifier_layer(output_logits)\n",
        "        predictions = F.softmax(logits, dim=1)\n",
        "        return logits, predictions\n"
      ],
      "metadata": {
        "id": "kY3kcZ6KdT9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import Adam\n",
        "import math\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the saved model\n",
        "num_features = X_train_tensor.shape[1]\n",
        "model = TabNetModel(num_features=num_features, num_classes=2)\n",
        "model.load_state_dict(torch.load('path_to_save_model/tabnet_with_lora.pt'))\n",
        "model = model.to(device)\n",
        "\n",
        "# Freeze the first LoRA layer\n",
        "for name, param in model.named_parameters():\n",
        "    if 'feature_transform_linear1.U' in name or 'feature_transform_linear1.V' in name:\n",
        "        param.requires_grad = False\n",
        "    else:\n",
        "        param.requires_grad = True\n",
        "\n",
        "# Create DataLoader for the new dataset\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.02)\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch = X_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, _ = model.encoder(X_batch)\n",
        "            loss = loss_function(model.classify(output)[0], y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "train_model(model, train_loader)\n",
        "\n",
        "# Save the model with the newly trained LoRA layers\n",
        "torch.save(model.state_dict(), 'path_to_save_model/tabnet_with_new_lora.pt')\n",
        "\n",
        "# Zero-shot testing on the new dataset\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    X_test_tensor = X_test_tensor.to(device)\n",
        "    y_test_tensor = y_test_tensor.to(device)\n",
        "    output, _ = model.encoder(X_test_tensor)\n",
        "    logits, predictions = model.classify(output)\n",
        "    predicted_labels = torch.argmax(predictions, dim=1)\n",
        "\n",
        "# Convert predictions and labels to CPU for sklearn metrics\n",
        "predicted_labels_cpu = predicted_labels.cpu()\n",
        "y_test_tensor_cpu = y_test_tensor.cpu()\n",
        "\n",
        "# Evaluate performance\n",
        "accuracy = accuracy_score(y_test_tensor_cpu, predicted_labels_cpu)\n",
        "precision = precision_score(y_test_tensor_cpu, predicted_labels_cpu, average='weighted')\n",
        "recall = recall_score(y_test_tensor_cpu, predicted_labels_cpu, average='weighted')\n",
        "f1 = f1_score(y_test_tensor_cpu, predicted_labels_cpu, average='weighted')\n",
        "\n",
        "print(f'Zero-shot testing accuracy: {accuracy:.4f}')\n",
        "print(f'Zero-shot testing precision: {precision:.4f}')\n",
        "print(f'Zero-shot testing recall: {recall:.4f}')\n",
        "print(f'Zero-shot testing F1 score: {f1:.4f}')\n"
      ],
      "metadata": {
        "id": "jqsp6EPLe89A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}